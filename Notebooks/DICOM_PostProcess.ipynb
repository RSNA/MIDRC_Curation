{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets\n",
    "!pip install matplotlib ipywidgets\n",
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import botocore\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application Beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create log file\n",
    "def create_log_file(log_file_name):\n",
    "    logging.basicConfig(filename=log_file_name, level=logging.INFO,\n",
    "                        format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Function to prompt user for information\n",
    "def prompt_user():\n",
    "    name = input(\"Enter your name: \")\n",
    "    project_name = input(\"Enter project name: \")\n",
    "    log_date = input(\"Enter log file date (YYYY-MM-DD): \")\n",
    "    output_path = input(\"Enter the output directory path: \")\n",
    "    source_path = input(\"Enter the source directory path (local or S3 bucket): \")\n",
    "    return name, project_name, log_date, output_path, source_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to append to project report CSV file\n",
    "def append_to_project_report(module_name, summary, output_path, user_name):\n",
    "    report_file = os.path.join(output_path, \"project_report.csv\")\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with open(report_file, \"a\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([now, user_name, module_name, summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions from the second notebook\n",
    "\n",
    "# Function 1: Verify DICOM files\n",
    "def verify_dicom_files(directory, output_path, project_report_file=None):\n",
    "    \"\"\"\n",
    "    Verify DICOM files in a directory (local or S3 bucket).\n",
    "    \n",
    "    Args:\n",
    "    - directory (str): The root directory to search for DICOM files.\n",
    "    - output_path (str): The path to save the output CSV file and log file.\n",
    "    - project_report_file (str): The path to the project report file.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Setup logging\n",
    "    log_file = os.path.join(output_path, \"dicom_processing.log\")\n",
    "    logging.basicConfig(filename=log_file, level=logging.INFO,\n",
    "                        format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    \n",
    "    logging.info(f\"Verifying DICOM files in directory: {directory}\")\n",
    "    \n",
    "    # Create an empty list to store verification results\n",
    "    verification_results = []\n",
    "    \n",
    "    # Iterate over all DICOM files in the directory\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".dcm\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    # Verify DICOM file\n",
    "                    dicom_data = pydicom.dcmread(file_path)\n",
    "                    \n",
    "                    # Add verification result to the list\n",
    "                    verification_results.append({\n",
    "                        \"File\": file_path,\n",
    "                        \"Verification\": \"Passed\"\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error verifying DICOM file {file_path}: {str(e)}\")\n",
    "                    verification_results.append({\n",
    "                        \"File\": file_path,\n",
    "                        \"Verification\": \"Failed\"\n",
    "                    })\n",
    "                    continue\n",
    "    \n",
    "    # Convert the list of verification results to a DataFrame\n",
    "    verification_df = pd.DataFrame(verification_results)\n",
    "    \n",
    "    # Save verification results to a CSV file\n",
    "    verification_csv_file = os.path.join(output_path, \"dicom_verification_results.csv\")\n",
    "    verification_df.to_csv(verification_csv_file, index=False)\n",
    "    \n",
    "    logging.info(f\"Verification results saved to {verification_csv_file}\")\n",
    "    print(f\"Verification results saved to {verification_csv_file}\")\n",
    "\n",
    "    if project_report_file:\n",
    "        try:\n",
    "            with open(project_report_file, 'a', newline='') as csvfile:\n",
    "                fieldnames = ['Module', 'Summary', 'Timestamp']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writerow({\n",
    "                    'Module': 'Verify DICOM Files',\n",
    "                    'Summary': f\"Executed Verify DICOM Files {directory}\",\n",
    "                    'Timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                })\n",
    "        except PermissionError as e:\n",
    "            print(f\"PermissionError when writing to project report file: {e}. Please ensure it is not open in another program and that you have the necessary permissions.\")\n",
    "\n",
    "\n",
    "# Function 2: Check for duplicate SOP Instance UIDs\n",
    "def check_duplicate_sop_uids(directory, output_path, project_report_file=None):\n",
    "    \"\"\"\n",
    "    Check for duplicate SOP Instance UIDs in DICOM files within a directory (local or S3 bucket).\n",
    "    \n",
    "    Args:\n",
    "    - directory (str): The root directory to search for DICOM files.\n",
    "    - output_path (str): The path to save the output CSV file and log file.\n",
    "    - project_report_file (str): The path to the project report file.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Setup logging\n",
    "    log_file = os.path.join(output_path, \"dicom_processing.log\")\n",
    "    logging.basicConfig(filename=log_file, level=logging.INFO,\n",
    "                        format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    \n",
    "    logging.info(f\"Checking for duplicate SOP Instance UIDs in directory: {directory}\")\n",
    "    \n",
    "    # Create a defaultdict to store lists of files with duplicate SOP UID for each UID\n",
    "    duplicate_uids = defaultdict(list)\n",
    "    \n",
    "    # Create a dictionary to store duplicate SOPs and corresponding paths\n",
    "    duplicates_dict = {}\n",
    "    \n",
    "    # Iterate over all DICOM files in the directory\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".dcm\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    # Read DICOM file and extract SOP Instance UID\n",
    "                    dicom_data = pydicom.dcmread(file_path)\n",
    "                    sop_instance_uid = dicom_data.SOPInstanceUID\n",
    "                    \n",
    "                    # Check if SOP Instance UID already exists in the defaultdict\n",
    "                    if sop_instance_uid in duplicate_uids:\n",
    "                        # If exists, add file path to the list\n",
    "                        duplicate_uids[sop_instance_uid].append(file_path)\n",
    "                        # Add to the duplicates dictionary\n",
    "                        duplicates_dict.setdefault(sop_instance_uid, []).append(file_path)\n",
    "                    else:\n",
    "                        # If not exists, create a new list with the file path\n",
    "                        duplicate_uids[sop_instance_uid] = [file_path]\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing DICOM file {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    # Filter the dictionary to include only duplicates\n",
    "    duplicates_dict = {key: value for key, value in duplicates_dict.items() if len(value) > 1}\n",
    "    \n",
    "    # Save duplicate SOP Instance UIDs and corresponding paths to a CSV file\n",
    "    duplicate_uids_csv_file = os.path.join(output_path, \"duplicate_sop_instance_uids.csv\")\n",
    "    with open(duplicate_uids_csv_file, \"w\", newline=\"\") as csvfile:\n",
    "        fieldnames = [\"SOPInstanceUID\", \"FilePaths\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for uid, file_paths in duplicates_dict.items():\n",
    "            writer.writerow({\"SOPInstanceUID\": uid, \"FilePaths\": \", \".join(file_paths)})\n",
    "    \n",
    "    logging.info(f\"Duplicate SOP Instance UIDs and corresponding paths saved to {duplicate_uids_csv_file}\")\n",
    "    print(f\"Duplicate SOP Instance UIDs and corresponding paths saved to {duplicate_uids_csv_file}\")\n",
    "\n",
    "    if project_report_file:\n",
    "        try:\n",
    "            with open(project_report_file, 'a', newline='') as csvfile:\n",
    "                fieldnames = ['Module', 'Summary', 'Timestamp']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writerow({\n",
    "                    'Module': 'Check Duplicate SOP Instance UIDs',\n",
    "                    'Summary': f\"Executed Check Duplicate SOP Instance UIDs {directory}\",\n",
    "                    'Timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                })\n",
    "        except PermissionError as e:\n",
    "            print(f\"PermissionError when writing to project report file: {e}. Please ensure it is not open in another program and that you have the necessary permissions.\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# Function 3: Check DICOM consistency\n",
    "def check_dicom_consistency(directory, output_path, project_report_file=None):\n",
    "    \"\"\"\n",
    "    Perform basic and extended consistency checks for a directory containing folders of DICOM files.\n",
    "\n",
    "    Args:\n",
    "    - directory: Path to the directory containing folders of DICOM files.\n",
    "    - output_path: Path to save the output CSV file.\n",
    "    - project_report_file (str): The path to the project report file.\n",
    "\n",
    "    Returns:\n",
    "    - csv_file_path: Path to the output CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Dictionary to store errors\n",
    "    errors = defaultdict(list)\n",
    "\n",
    "    # Iterate over each folder (DICOM series) in the directory\n",
    "    for series_folder in os.listdir(directory):\n",
    "        series_path = os.path.join(directory, series_folder)\n",
    "\n",
    "        if not os.path.isdir(series_path):\n",
    "            continue\n",
    "\n",
    "        # Collect DICOM files within the series folder\n",
    "        dicom_files = [f for f in os.listdir(series_path) if f.endswith('.dcm')]\n",
    "\n",
    "        # Check if there are DICOM files in the series folder\n",
    "        if not dicom_files:\n",
    "            errors[series_folder].append((None, \"No DICOM files found in this series folder.\"))\n",
    "            continue\n",
    "\n",
    "        # Initialize variables to store attributes for consistency checks\n",
    "        attributes = defaultdict(list)\n",
    "        image_positions = []\n",
    "\n",
    "        # Iterate over DICOM files in the series folder\n",
    "        for dicom_file in tqdm(dicom_files, desc=f'Processing {series_folder}'):\n",
    "            file_path = os.path.join(series_path, dicom_file)\n",
    "\n",
    "            try:\n",
    "                # Read DICOM file\n",
    "                dicom_data = pydicom.dcmread(file_path)\n",
    "\n",
    "                # Check consistency of essential attributes\n",
    "                essential_attributes = ['PatientID', 'StudyInstanceUID', 'SeriesInstanceUID', 'SOPInstanceUID']\n",
    "                for attribute in essential_attributes:\n",
    "                    if attribute not in dicom_data:\n",
    "                        errors[series_folder].append((file_path, f\"Missing {attribute} in DICOM file: {dicom_file}\"))\n",
    "                    else:\n",
    "                        attributes[attribute].append(dicom_data[attribute].value)\n",
    "\n",
    "                # Additional consistency checks\n",
    "                if 'StudyDate' in dicom_data:\n",
    "                    attributes['StudyDate'].append(dicom_data.StudyDate)\n",
    "                if 'StudyTime' in dicom_data:\n",
    "                    attributes['StudyTime'].append(dicom_data.StudyTime)\n",
    "                if 'SeriesDate' in dicom_data:\n",
    "                    attributes['SeriesDate'].append(dicom_data.SeriesDate)\n",
    "                if 'SeriesTime' in dicom_data:\n",
    "                    attributes['SeriesTime'].append(dicom_data.SeriesTime)\n",
    "                if 'Modality' in dicom_data:\n",
    "                    attributes['Modality'].append(dicom_data.Modality)\n",
    "                if 'ImagePositionPatient' in dicom_data:\n",
    "                    image_positions.append(dicom_data.ImagePositionPatient)\n",
    "                if 'ImageOrientationPatient' in dicom_data:\n",
    "                    attributes['ImageOrientationPatient'].append(dicom_data.ImageOrientationPatient)\n",
    "                if 'PixelSpacing' in dicom_data:\n",
    "                    attributes['PixelSpacing'].append(dicom_data.PixelSpacing)\n",
    "                if 'SOPClassUID' in dicom_data:\n",
    "                    attributes['SOPClassUID'].append(dicom_data.SOPClassUID)\n",
    "\n",
    "                # Check image consistency\n",
    "                if len(image_positions) > 1 and len(set(image_positions)) != 1:\n",
    "                    errors[series_folder].append((file_path, \"Inconsistent ImagePositionPatient values across DICOM files.\"))\n",
    "                \n",
    "                # You can add more checks for image consistency based on your specific requirements\n",
    "\n",
    "            except Exception as e:\n",
    "                errors[series_folder].append((file_path, f\"Error processing DICOM file {dicom_file}: {str(e)}\"))\n",
    "\n",
    "    # Write errors to CSV file\n",
    "    csv_file_path = os.path.join(output_path, 'dicom_consistency_errors.csv')\n",
    "    with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['SeriesFolder', 'FilePath', 'Error'])\n",
    "        for series_folder, error_list in errors.items():\n",
    "            for error in error_list:\n",
    "                writer.writerow([series_folder, error[0], error[1]])\n",
    "\n",
    "    print(f\"Output CSV file saved to: {csv_file_path}\")\n",
    "\n",
    "    if project_report_file:\n",
    "        try:\n",
    "            with open(project_report_file, 'a', newline='') as csvfile:\n",
    "                fieldnames = ['Module', 'Summary', 'Timestamp']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writerow({\n",
    "                    'Module': 'Check DICOM Consistency',\n",
    "                    'Summary': f\"Executed Check DICOM Consistency: Checking DICOM consistency in {directory}\",\n",
    "                    'Timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                })\n",
    "        except PermissionError as e:\n",
    "            print(f\"PermissionError when writing to project report file: {e}. Please ensure it is not open in another program and that you have the necessary permissions.\")\n",
    "\n",
    "\n",
    "    return csv_file_path\n",
    "\n",
    "# Function 4: Verify DICOM IOD data consistency\n",
    "def verify_dicom_iod_data(directory, output_path, location='local', project_report_file=None):\n",
    "    \"\"\"\n",
    "    Verify DICOM IOD data consistency within DICOM files in a directory (local or S3 bucket).\n",
    "    \n",
    "    Args:\n",
    "    - directory (str): The root directory to search for DICOM files.\n",
    "    - output_path (str): The path to save the output log file.\n",
    "    - location (str): The location type ('local' or 's3'). Default is 'local'.\n",
    "    - project_report_file (str): The path to the project report file.\n",
    "    \n",
    "    Returns:\n",
    "    - iod_verification_report (dict): Dictionary containing IOD verification results.\n",
    "    \"\"\"\n",
    "    # Setup logging\n",
    "    log_file = os.path.join(output_path, \"dicom_processing.log\")\n",
    "    logging.basicConfig(filename=log_file, level=logging.INFO,\n",
    "                        format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    \n",
    "    logging.info(f\"Verifying DICOM IOD data consistency in {location} directory: {directory}\")\n",
    "    \n",
    "    # Dictionary to store verification results\n",
    "    iod_verification_report = {}\n",
    "    \n",
    "    # Iterate over all DICOM files in the directory\n",
    "    for root, dirs, files in tqdm(os.walk(directory)):\n",
    "        for file in files:\n",
    "            if file.endswith(\".dcm\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    # Read DICOM file and perform IOD data consistency verification\n",
    "                    dicom_data = pydicom.dcmread(file_path)\n",
    "                    \n",
    "                    # Example verification (add your verifications here)\n",
    "                    if \"PixelData\" not in dicom_data:\n",
    "                        iod_verification_report[file_path] = \"Missing PixelData\"\n",
    "                        logging.warning(f\"Missing PixelData in DICOM file: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing DICOM file {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    # Save verification report to a CSV file\n",
    "    verification_report_csv = os.path.join(output_path, \"iod_verification_report.csv\")\n",
    "    with open(verification_report_csv, \"w\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"File\", \"Issue\"])\n",
    "        for file_path, issue in iod_verification_report.items():\n",
    "            writer.writerow([file_path, issue])\n",
    "    \n",
    "    logging.info(f\"IOD verification report saved to {verification_report_csv}\")\n",
    "    print(f\"IOD verification report saved to {verification_report_csv}\")\n",
    "\n",
    "    if project_report_file:\n",
    "        try:\n",
    "            with open(project_report_file, 'a', newline='') as csvfile:\n",
    "                fieldnames = ['Module', 'Summary', 'Timestamp']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writerow({\n",
    "                    'Module': 'Verify DICOM IOD Data Consistency',\n",
    "                    'Summary': f\"Executed Verify DICOM IOD Data Consistency in {directory}\",\n",
    "                    'Timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                })\n",
    "        except PermissionError as e:\n",
    "            print(f\"PermissionError when writing to project report file: {e}. Please ensure it is not open in another program and that you have the necessary permissions.\")\n",
    "\n",
    "    return iod_verification_report\n",
    "\n",
    "# Function 5: Remove PHI info from DICOM metadata\n",
    "def aggregate_dicom_metadata(directory, output_path, location='local', project_report_file=None):\n",
    "    \"\"\"\n",
    "    Aggregate DICOM metadata from the source directory and save it to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "    - directory (str): The root directory containing DICOM files.\n",
    "    - output_path (str): The path to save the aggregated metadata CSV file.\n",
    "    - location (str): The location type ('local' or 's3'). Default is 'local'.\n",
    "    - project_report_file (str): The path to the project report file.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Setup logging\n",
    "    log_file = os.path.join(output_path, \"dicom_processing.log\")\n",
    "    logging.basicConfig(filename=log_file, level=logging.INFO,\n",
    "                        format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    \n",
    "    logging.info(f\"Aggregating DICOM metadata from {location} directory: {directory}\")\n",
    "    \n",
    "    # Initialize a list to store DICOM metadata dictionaries\n",
    "    metadata_dicts = []\n",
    "    \n",
    "    # Iterate over all DICOM files in the directory\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".dcm\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    dicom_data = pydicom.dcmread(file_path)\n",
    "                    \n",
    "                    # Convert DICOM metadata to a dictionary and append to the list\n",
    "                    metadata_dict = dicom_data.__dict__\n",
    "                    metadata_dict['File'] = file\n",
    "                    metadata_dicts.append(metadata_dict)\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing DICOM file {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    # Save aggregated metadata dictionaries to a CSV file\n",
    "    aggregated_metadata_file = os.path.join(output_path, \"aggregated_dicom_metadata.csv\")\n",
    "    fieldnames = metadata_dicts[0].keys() if metadata_dicts else []\n",
    "    with open(aggregated_metadata_file, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(metadata_dicts)\n",
    "    \n",
    "    print(f\"Aggregated DICOM metadata saved to: {aggregated_metadata_file}\")\n",
    "    logging.info(f\"Aggregated DICOM metadata saved to: {aggregated_metadata_file}\")\n",
    "\n",
    "    if project_report_file:\n",
    "        try:\n",
    "            with open(project_report_file, 'a', newline='') as csvfile:\n",
    "                fieldnames = ['Module', 'Summary', 'Timestamp']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writerow({\n",
    "                    'Module': 'Remove PHI',\n",
    "                    'Summary': f\"Executed Remove PHI in {directory}\",\n",
    "                    'Timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                })\n",
    "        except PermissionError as e:\n",
    "            print(f\"PermissionError when writing to project report file: {e}. Please ensure it is not open in another program and that you have the necessary permissions.\")\n",
    "\n",
    "\n",
    "# Function 6: Generate summary of DICOM tags\n",
    "def generate_summary(directory, output_path, project_report_file=None):\n",
    "    logging.info(f\"Generating summary of DICOM tags in {directory}\")\n",
    "    \n",
    "    # Initialize an empty list to store DICOM metadata\n",
    "    dicom_metadata = []\n",
    "    \n",
    "    # Iterate over all DICOM files in the directory\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".dcm\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    dicom_data = pydicom.dcmread(file_path)\n",
    "                    \n",
    "                    # Extract metadata from DICOM file\n",
    "                    metadata = {\n",
    "                        \"File\": file_path,\n",
    "                        \"PatientID\": dicom_data.get(\"PatientID\", \"\"),\n",
    "                        \"PatientName\": dicom_data.get(\"PatientName\", \"\"),\n",
    "                        \"StudyDate\": dicom_data.get(\"StudyDate\", \"\"),\n",
    "                        # Add more DICOM tags as needed\n",
    "                    }\n",
    "                    dicom_metadata.append(metadata)\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing DICOM file {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    # Convert the list of metadata dictionaries to a DataFrame\n",
    "    df = pd.DataFrame(dicom_metadata)\n",
    "    \n",
    "    # Save the DataFrame to a CSV file at the specified output path\n",
    "    output_file = \"dicom_summary.csv\"\n",
    "    output_file_path = os.path.join(output_path, output_file)\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "    \n",
    "    logging.info(f\"Summary of DICOM tags saved to {output_file_path}\")\n",
    "    print(f\"Summary of DICOM tags saved to {output_file_path}\")\n",
    "\n",
    "    if project_report_file:\n",
    "        try:\n",
    "            with open(project_report_file, 'a', newline='') as csvfile:\n",
    "                fieldnames = ['Module', 'Summary', 'Timestamp']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writerow({\n",
    "                    'Module': 'Generate Summary',\n",
    "                    'Summary': f\"Executed Generate Summary: Generating summary of DICOM tags in {directory}\",\n",
    "                    'Timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                })\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error writing to project report file {project_report_file}: {str(e)}\")\n",
    "\n",
    "\n",
    "    return output_file_path\n",
    "\n",
    "# Function 7: Rename DICOM files\n",
    "def rename_dicom_files(input_directory, output_path, project_report_file=None):\n",
    "    logging.info(f\"Renaming DICOM files in {input_directory}\")\n",
    "    \n",
    "    # Initialize a list to store rename log entries\n",
    "    rename_log = []\n",
    "    \n",
    "    # Iterate over all DICOM files in the directory\n",
    "    for root, dirs, files in os.walk(input_directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".dcm\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    dicom_data = pydicom.dcmread(file_path)\n",
    "                    \n",
    "                    # Extract SOP Instance UID\n",
    "                    sop_instance_uid = dicom_data.SOPInstanceUID\n",
    "                    \n",
    "                    # Extract patient's age and check if it's empty or > 89\n",
    "                    patient_age = dicom_data.PatientAge\n",
    "                    if not patient_age or int(patient_age) > 89:\n",
    "                        patient_age = ''\n",
    "                    \n",
    "                    # Generate new filename based on SOP Instance UID and empty age\n",
    "                    new_filename = f\"{sop_instance_uid}_{patient_age}.dcm\"\n",
    "                    \n",
    "                    # Rename the DICOM file\n",
    "                    new_file_path = os.path.join(root, new_filename)\n",
    "                    os.rename(file_path, new_file_path)\n",
    "                    \n",
    "                    # Log the renaming action\n",
    "                    rename_log.append((file_path, new_file_path))\n",
    "                    logging.info(f\"Renamed {file_path} to {new_file_path}\")\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error renaming DICOM file {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    # Save the rename log to a CSV file at the specified output path\n",
    "    csv_file_path = os.path.join(output_path, 'dicom_rename_log.csv')\n",
    "    with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Previous Name', 'New Name', 'File Path'])\n",
    "        for old_name, new_name in rename_log:\n",
    "            writer.writerow([os.path.basename(old_name), os.path.basename(new_name), new_name])\n",
    "    \n",
    "    logging.info(f\"Rename log saved to {csv_file_path}\")\n",
    "    print(f\"Rename log saved to {csv_file_path}\")\n",
    "\n",
    "    if project_report_file:\n",
    "        try:\n",
    "            with open(project_report_file, 'a', newline='') as csvfile:\n",
    "                fieldnames = ['Module', 'Summary', 'Timestamp']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writerow({\n",
    "                    'Module': 'Rename DICOM Files',\n",
    "                    'Summary': f\"Executed Rename DICOM Files in {directory}\",\n",
    "                    'Timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                })\n",
    "        except PermissionError as e:\n",
    "            print(f\"PermissionError when writing to project report file: {e}. Please ensure it is not open in another program and that you have the necessary permissions.\")\n",
    "\n",
    "    return csv_file_path\n",
    "\n",
    "\n",
    "# Function 8: Generate DICOM metadata Extract CSV file\n",
    "def generate_DME(directory, output_path, location='local', project_report_file=None):\n",
    "    logging.info(f\"Generating DICOM metadata CSV file from {location} directory: {directory}\")\n",
    "\n",
    "    metadata_list = []\n",
    "    total_files = sum(len(files) for _, _, files in os.walk(directory))\n",
    "    progress_bar = tqdm(total=total_files, desc='Processing DICOM files', unit='files')\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".dcm\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    dicom_data = pydicom.dcmread(file_path)\n",
    "                    metadata = {\n",
    "                        \"file_name\": os.path.basename(file_path),\n",
    "                        \"accession_number\": str(dicom_data.get(\"AccessionNumber\", \"\")),\n",
    "                        \"acquisition_type\": str(dicom_data.get(\"AcquisitionType\", \"\")),\n",
    "                        \"body_part_examined\": str(dicom_data.get(\"BodyPartExamined\", \"\")),\n",
    "                        \"case_ids\": str(dicom_data.get(\"PatientID\", \"\")),\n",
    "                        \"contrast_bolus_agent\": str(dicom_data.get(\"ContrastBolusAgent\", \"\")),\n",
    "                        \"patient_position\": str(dicom_data.get(\"PatientPosition\", \"\")),\n",
    "                        \"convolution_kernel\": \"_\".join(dicom_data.get(\"ConvolutionKernel\", []) if dicom_data.get(\"ConvolutionKernel\") else \"\"),\n",
    "                        \"detector_type\": str(dicom_data.get(\"DetectorType\", \"\")),\n",
    "                        \"exposure_modulation_type\": str(dicom_data.get(\"ExposureModulationType\", \"\")),\n",
    "                        \"image_type\": \"_\".join(dicom_data.get(\"ImageType\", []) if dicom_data.get(\"ImageType\") else \"\"),\n",
    "                        \"imager_pixel_spacing\": str(dicom_data.get(\"ImagerPixelSpacing\", \"\")),\n",
    "                        \"lossy_image_compression\": str(dicom_data.get(\"LossyImageCompression\", \"\")),\n",
    "                        \"manufacturer\": str(dicom_data.get(\"Manufacturer\", \"\")),\n",
    "                        \"manufacturer_model_name\": str(dicom_data.get(\"ManufacturerModelName\", \"\")),\n",
    "                        \"modality\": str(dicom_data.get(\"Modality\", \"\")),\n",
    "                        \"sop_instance_uid\": str(dicom_data.get(\"SOPInstanceUID\", \"\")),\n",
    "                        \"pixel_spacing\": str(dicom_data.get(\"PixelSpacing\", \"\")),\n",
    "                        \"series_description\": str(dicom_data.get(\"SeriesDescription\", \"\")),\n",
    "                        \"series_uid\": str(dicom_data.get(\"SeriesInstanceUID\", \"\")),\n",
    "                        \"slice_thickness\": str(dicom_data.get(\"SliceThickness\", \"\")),\n",
    "                        \"spacing_between_slices\": str(dicom_data.get(\"SpacingBetweenSlices\", \"\")),\n",
    "                        \"spatial_resolution\": str(dicom_data.get(\"SpatialResolution\", \"\")),\n",
    "                        \"study_description\": str(dicom_data.get(\"StudyDescription\", \"\")),\n",
    "                        \"study_uid\": str(dicom_data.get(\"StudyInstanceUID\", \"\")),\n",
    "                        \"view_position\": str(dicom_data.get(\"ViewPosition\", \"\")),\n",
    "                        \"study_date\": str(dicom_data.get(\"StudyDate\", \"\"))\n",
    "                    }\n",
    "                    metadata_list.append(metadata)\n",
    "                    progress_bar.update(1)\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error processing DICOM file {file_path}: {str(e)}\")\n",
    "\n",
    "    progress_bar.close()\n",
    "    metadata_df = pd.DataFrame(metadata_list)\n",
    "    output_file = os.path.join(output_path, \"DME.csv\")\n",
    "    metadata_df.to_csv(output_file, index=False)\n",
    "\n",
    "    logging.info(f\"Generated DICOM metadata CSV file: {output_file}\")\n",
    "    print(f\"Generated DICOM metadata CSV file: {output_file}\")\n",
    "\n",
    "    if project_report_file:\n",
    "        try:\n",
    "            with open(project_report_file, 'a', newline='') as csvfile:\n",
    "                fieldnames = ['Module', 'Summary', 'Timestamp']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                writer.writerow({\n",
    "                    'Module': 'Generate DME',\n",
    "                    'Summary': f\"Executed Generate DME in {directory}\",\n",
    "                    'Timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                })\n",
    "        except PermissionError as e:\n",
    "            print(f\"PermissionError when writing to project report file: {e}. Please ensure it is not open in another program and that you have the necessary permissions.\")\n",
    "\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to execute individual modules\n",
    "def execute_module(module_number, directory, output_path, project_report_file):\n",
    "    \"\"\"\n",
    "    Execute a specific DICOM processing module.\n",
    "    \n",
    "    Args:\n",
    "    - module_number (int): The number corresponding to the module to execute (1-8).\n",
    "    - directory (str): The root directory containing DICOM files.\n",
    "    - output_path (str): The path to save the output files.\n",
    "    - project_report_file (str): The path to the project report file.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    module_names = {\n",
    "        1: \"Verify DICOM Files\",\n",
    "        2: \"Check Duplicate SOP Instance UIDs\",\n",
    "        3: \"Check DICOM Consistency\",\n",
    "        4: \"Verify DICOM IOD Data Consistency\",\n",
    "        5: \"Remove PHI\",\n",
    "        6: \"Generate Summary\",\n",
    "        7: \"Rename DICOM Files\",\n",
    "        8: \"Generate DME\"\n",
    "    }\n",
    "    \n",
    "    if module_number in module_names:\n",
    "        print(f\"Executing Module {module_number}: {module_names[module_number]}\")\n",
    "        if module_number == 1:\n",
    "            verify_dicom_files(directory, output_path, project_report_file)\n",
    "        elif module_number == 2:\n",
    "            check_duplicate_sop_uids(directory, output_path, project_report_file)\n",
    "        elif module_number == 3:\n",
    "            check_dicom_consistency(directory, output_path, project_report_file)\n",
    "        elif module_number == 4:\n",
    "            verify_dicom_iod_data_consistency(directory, output_path, project_report_file)\n",
    "        elif module_number == 5:\n",
    "            remove_phi(directory, output_path, project_report_file)\n",
    "        elif module_number == 6:\n",
    "            generate_summary(directory, output_path, project_report_file)\n",
    "        elif module_number == 7:\n",
    "            rename_dicom_files(directory, output_path, project_report_file)\n",
    "        elif module_number == 8:\n",
    "            generate_dme(directory, output_path, project_report_file)\n",
    "    else:\n",
    "        print(\"Invalid choice. Please enter a number between 1 and 8.\")\n",
    "\n",
    "# Function to execute all modules with option to skip\n",
    "def execute_all_modules(source_path, output_path):\n",
    "    print(\"Executing all functions in succession with option to skip each step:\")\n",
    "    for i in range(1, 9):\n",
    "        choice = input(f\"Execute module {i}? (yes/no): \")\n",
    "        if choice.lower() == 'yes':\n",
    "            execute_module(i, source_path, output_path)\n",
    "        else:\n",
    "            print(f\"Skipping module {i}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(name=None, project_name=None, log_date=None, output_path=None, source_path=None):\n",
    "    \"\"\"\n",
    "    Main function to execute the DICOM processing tool.\n",
    "\n",
    "    Args:\n",
    "    - name (str): User's name.\n",
    "    - project_name (str): Name of the project.\n",
    "    - log_date (str): Date for the log file (YYYY-MM-DD).\n",
    "    - output_path (str): Output directory path.\n",
    "    - source_path (str): Path to the source DICOM files.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    if not all([name, project_name, log_date, output_path, source_path]):\n",
    "        name, project_name, log_date, output_path, source_path = prompt_user()\n",
    "\n",
    "    log_file_name = f\"{project_name}_log_{log_date}.csv\"\n",
    "    log_file_path = os.path.join(output_path, log_file_name)\n",
    "\n",
    "    create_log_file(log_file_path)\n",
    "\n",
    "    project_report_name = f\"{project_name}_report_{log_date}.csv\"\n",
    "    project_report_file = os.path.join(output_path, project_report_name)\n",
    "\n",
    "    print(f\"Hello, {name}! Welcome to {project_name} DICOM Processing Tool.\")\n",
    "    print(\"Choose an option:\")\n",
    "    print(\"1. Execute individual modules\")\n",
    "    print(\"2. Execute all functions in succession with option to skip\")\n",
    "    option = int(input(\"Enter your choice (1-2): \"))\n",
    "\n",
    "    if option == 1:\n",
    "        module_number = int(input(\"Enter the module number you want to execute (1-8): \"))\n",
    "        execute_module(module_number, source_path, output_path, project_report_file)\n",
    "    elif option == 2:\n",
    "        execute_all_modules(source_path, output_path, project_report_file)\n",
    "    else:\n",
    "        print(\"Invalid choice. Please enter 1 or 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute main function\n",
    "if __name__ == \"__main__\":\n",
    "   main()\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
